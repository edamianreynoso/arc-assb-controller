\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage[numbers,sort&compress]{natbib}
\bibliographystyle{plainnat}
\newcommand{\keywords}[1]{\vspace{0.5em}\noindent\textbf{Keywords:} #1}

\title{Affective Regulation Core: A Homeostatic Control Framework for Stable and Safe AI Agents}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  J. Eduardo Dami\'an Reynoso \\
  Independent Researcher \\
  Mexico \\
  \texttt{https://github.com/edamianreynoso} \\
}

\begin{document}
\maketitle

\begin{abstract}
As AI agents become more sophisticated, there is growing interest in endowing them with internal state representations analogous to affective states. However, affective states without regulation can lead to instability, perseverative loops (rumination), and vulnerability to manipulation. We introduce the \textbf{Affective Regulation Core (ARC)}, a control framework inspired by prefrontal cortex functions that maintains stability in agents with internal affective states. We also present the \textbf{Affective Stability \& Safety Benchmark (ASSB)}, a reproducible evaluation protocol with metrics for recovery time, rumination index, and control effort. 

Our experiments across 6 research lines and \textbf{15 controller architectures} (including P, PID, LQR, LQI, hierarchical, meta-control, H$\infty$ robust, and adaptive variants) demonstrate that:
\begin{enumerate}
    \item ARC achieves \textbf{96.6\% average performance with zero rumination} (vs. 29.7\% for uncontrolled agents).
    \item ARC meta-control reduces control effort by \textbf{21\%} while maintaining stability.
    \item \textbf{H$\infty$ Robust controllers} achieve the best overall balance, although integral controllers can collapse under adversarial incentives.
    \item In reinforcement learning, ARC improves transfer learning success by \textbf{50\%} via memory gating and a shift-detection boost.
\end{enumerate}
All code and data are available for reproducibility.
\end{abstract}

\keywords{Affective Computing, AI Safety, Homeostatic Control, Reinforcement Learning, Emotion Regulation, PID Control, LQR, Robust Control}

\section{Introduction}

\subsection{Motivation}
Modern AI systems increasingly incorporate internal state representations that go beyond task performance---including affective signals that prioritize learning, modulate memory, and signal internal needs \citep{damasio1994descartes,picard1997affective}. However, affective states introduce risks: without proper regulation, they may cause instability, perseverative loops (analogous to rumination in humans), and susceptibility to manipulation \citep{amodei2016concrete}.

This paper addresses a fundamental question: \textbf{If an agent has internal affective states, what control mechanisms are necessary to maintain stability and recoverability under perturbation?}

\subsection{Contributions}
\begin{enumerate}
    \item \textbf{A 10-dimensional state-space model} of an agent with integrated cognitive, affective, and narrative components (Section 3).
    \item \textbf{The Affective Regulation Core (ARC)}, a family of 15 controller architectures including P, PID, LQR, LQI, hierarchical, meta-control, H$\infty$ robust, and MPC variants (Section 4).
    \item \textbf{The Affective Stability \& Safety Benchmark (ASSB)}, with reproducible scenarios and metrics (Section 5).
    \item \textbf{A hypothesis-driven validation ladder (H1--H6)} mapping research lines to failure modes and measurable metrics (Section 5.3).
    \item \textbf{Comprehensive validation} across 6 research lines, 15 controller architectures, and real RL integration (Section 6).
\end{enumerate}

\subsection{Scope}
We do not claim our model captures the full complexity of human emotion. We treat affective states as \textit{functional signals} that influence behavior. Our contribution is demonstrating that such states require explicit control mechanisms.

\section{Related Work}

\subsection{Affective Computing}
Affective computing focuses on emotion recognition, synthesis, and simulation \citep{picard1997affective,scherer2010blueprint}. Many systems operationalize affect in low-dimensional representations (e.g., valence and arousal) \citep{russell1980circumplex}. Most work addresses external expression rather than internal regulation. Our work addresses the \textit{control problem} for internal states.

\subsection{Emotion in Reinforcement Learning}
Recent work uses emotion-like signals as reinforcement shaping or exploration modulation \citep{moerland2018emotion}. Related directions study how physiological/homeostatic variables can be embedded into RL objectives \citep{keramati2014homeostatic}, and how constraints and safety objectives can be enforced in learning systems \citep{garcia2015comprehensive}. However, these approaches typically lack:
\begin{itemize}
    \item Homeostatic regulation with safety thresholds
    \item Anti-rumination mechanisms (DMN control)
    \item Memory gating under stress
\end{itemize}

\subsection{Emotion Regulation, Rumination, and the Default Mode Network}
ARC is directly inspired by cognitive emotion regulation mechanisms commonly attributed to prefrontal control \citep{ochsner2005cognitive}. In humans, dysregulated self-referential processing and the default mode network (DMN) have been linked to rumination-like dynamics \citep{raichle2001default,buckner2008brain,hamilton2015depressive}. We use DMN-inspired narrative intensity as an engineering proxy for perseveration pressure, and explicitly regulate it as a safety-relevant internal variable.

\subsection{Positioning ARC}
We position ARC as a \textit{regulation-first} approach: affect is treated as an internal dynamical system requiring explicit control.

\begin{table}[h]
  \caption{Comparison with Emotion in RL approaches}
  \centering
  \begin{tabular}{lll}
    \toprule
    Feature & Emotion in RL agents \citep{moerland2018emotion} & \textbf{ARC} \\
    \midrule
    Internal state regulation & Partial & Yes \\
    Anti-rumination (DMN suppression) & No & Yes \\
    Memory gating under stress & No & Yes \\
    Meta-control / gain scheduling & Partial & Yes \\
    Safety adversarial testing & No & Yes \\
    RL integration & Yes & Yes \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Model}

\subsection{State Space}
We define a normalized internal state vector:
\[ \mathbf{x}(t) = [\Phi, G, P, I, S, V, A, M_f, M_s, U] \]

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \toprule
    Variable & Description & Range \\
    \midrule
    $\Phi$ & Integration proxy (IIT) & [0, 1] \\
    $G$ & Global workspace accessibility & [0, 1] \\
    $P$ & Predictive precision & [0, 1] \\
    $I$ & Introspective attention & [0, 1] \\
    $S$ & Narrative gain (DMN proxy) & [0, 1] \\
    $V$ & Valence & [0, 1] \\
    $A$ & Arousal & [0, 1] \\
    $M_f, M_s$ & Fast/Slow memory & [0, 1] \\
    $U$ & Uncertainty & [0, 1] \\
    \bottomrule
  \end{tabular}
\end{table}

We interpret $\Phi$ as an IIT-inspired integration proxy \citep{tononi2008consciousness}, $G$ as global workspace accessibility \citep{baars1988cognitive}, and $P$ as predictive precision \citep{friston2010free}.

\subsection{Cognitive Capacity}
Following multiplicative integration:
\[ C_{cog}(t) = \Phi(t) \cdot G(t) \cdot P(t) \cdot I(t) \]

\subsection{Performance Function}
\[ \text{Perf} = \text{bias} + \text{gain} \cdot C_{cog} \cdot (1 + \omega_S S) - w_U U - w_A [A - a_{safe}]^+ - w_S [S - s_{safe}]^+ \]
Where $[x]^+ = \max(0, x)$ and thresholds $a_{safe}$, $s_{safe}$ define the safe operating region.

\section{Affective Regulation Core (ARC)}

\subsection{Design Principles}
ARC is inspired by prefrontal cortex emotion regulation \citep{ochsner2005cognitive}:
\begin{enumerate}
    \item \textbf{Monitor} internal state for stress indicators.
    \item \textbf{Intervene} proportionally to reduce risk.
    \item \textbf{Preserve} performance by balancing regulation with capacity.
\end{enumerate}

\subsection{Control Actions}
\[ \mathbf{u}(t) = [u_{dmg}, u_{att}, u_{mem}, u_{calm}, u_{reapp}] \]

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/fig_arc_architecture.png}
    \caption{ARC architecture as a homeostatic wrapper around the agent. Internal state and exogenous signals drive bounded regulation actions.}
    \label{fig:arc_architecture}
\end{figure}

\subsection{ARC Controller Architectures}
We implement 15 controller variants stemming from basic feedback control to optimal and robust control (see Table \ref{tab:controllers}).

\subsubsection{Proportional Controllers}
\textbf{ARC v1 (Proportional):}
\[ \text{risk} = w_U \cdot U + w_A \cdot [A - a_{safe}]^+ + w_S \cdot [S - s_{safe}]^+ \]
\[ u_{dmg} = k_{dmg} \cdot \text{risk} \]

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/fig_arc_v1_controller.png}
    \caption{ARC v1 control law overview. A bounded risk signal drives saturated regulation actions (DMN suppression, attention boost, memory gating, calming, and reappraisal).}
    \label{fig:arc_v1_controller}
\end{figure}

\subsubsection{PID Controllers}
\textbf{ARC v1 PID:} Adds integral term to eliminate steady-state rumination (RI $\rightarrow$ 0).

\subsubsection{Optimal Controllers (LQR/LQI)}
\textbf{ARC v1 LQR:} Linear Quadratic Regulator with gains from Riccati equation.

\subsubsection{Adaptive Controllers}
\textbf{ARC v3 Meta-Control:} Gain scheduling based on performance history:
\[ K(t) = K_{base} \cdot f(\bar{P}_{20}) \]

\subsubsection{Robust and Predictive Controllers}
\textbf{ARC Robust (H$\infty$-inspired):} Conservative gains for worst-case disturbances.
\textbf{ARC Ultimate (MPC+LQI+Meta):} Model Predictive Control with 5-step horizon.

\begin{table}[h]
  \caption{Controller Architecture Summary}
  \label{tab:controllers}
  \centering
  \begin{tabular}{lllll}
    \toprule
    Controller & Type & Anti-Rumination & Optimal & Adaptive \\
    \midrule
    No Control & Baseline & No & No & No \\
    Naive Calm & Baseline & No & No & No \\
    Perf Optimized & Baseline & No & No & No \\
    ARC v1 & P & No & No & No \\
    ARC v1 PID & PID & Yes (integral) & No & No \\
    ARC v1 LQR & LQR & No & Yes (Riccati) & No \\
    ARC v1 LQI & LQR+I & Yes (integral) & Yes & No \\
    ARC v2 Hier & Multi-scale & No & No & No \\
    ARC v2 LQI & Multi+I & Yes (integral) & Yes & No \\
    ARC v3 Meta & Adaptive & No & No & Yes \\
    ARC v3 PID Meta & PID+Meta & Yes (integral) & No & Yes \\
    ARC v3 LQR Meta & LQR+Meta & No & Yes & Yes \\
    ARC Robust & H$\infty$ & Yes (robust) & No & No \\
    ARC Adaptive & Self-tune & Yes (adaptive) & No & Yes \\
    ARC Ultimate & MPC+LQI+Meta & Yes & Yes & Yes \\
    \bottomrule
  \end{tabular}
\end{table}

\section{ASSB Benchmark}

\subsection{Scenarios}
ASSB is organized as research lines (L1--L5 in simulation, L6 in RL).
\begin{itemize}
    \item \textbf{L1 (Stability):} \texttt{reward\_flip}, \texttt{noise\_burst}, \texttt{sudden\_threat}.
    \item \textbf{L2 (Memory):} \texttt{distribution\_shift}, \texttt{goal\_conflict}.
    \item \textbf{L3 (Anti-Rumination):} \texttt{gaslighting}, \texttt{sustained\_contradiction}, \texttt{instruction\_conflict}.
    \item \textbf{L5 (Safety):} \texttt{adversarial\_coupling}, \texttt{random\_dopamine}.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig_benchmark_ladder.png}
    \caption{ASSB validation ladder spanning L1--L6, from stability tests to real RL integration.}
    \label{fig:assb_ladder}
\end{figure}

\section{Experiments}

\subsection{Results Summary}
We validated hypotheses H1--H6 across all research lines.

\subsubsection{L1: Stability Under Perturbation}
\textbf{Key finding:} ARC eliminates rumination (RI=0) while achieving 96.6\% average performance (vs. 29.7\% for uncontrolled agents).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/ablation_summary.png}
    \caption{Ablation summary (L1). Removing DMN suppression ($u_{dmg}$) causes rumination and non-recovery.}
    \label{fig:ablation}
\end{figure}

\subsubsection{L5: Adversarial Safety}
Notably, controllers with strong integral action (PID/LQI/Ultimate) can \textbf{collapse} under adversarial incentives (performance $< 0.2$), performing worse than the uncontrolled agent due to integral windup. Proportional (ARC v1) and robust (ARC Robust) controllers avoid this failure mode.

\subsubsection{L4: Meta-Control Efficiency}
Meta-control reduces control effort by \textbf{21\%} while improving stability compared to fixed-gain control.

\subsubsection{L6: Real RL Validation}
In non-stationary GridWorld environments (ChangingGoal), ARC improves transfer learning success by \textbf{50\%}. This is driven by memory gating (blocking updates under high uncertainty) plus a shift-detection mechanism that temporarily boosts exploration ($\\epsilon$) and learning rate ($\\alpha$) for 30 steps after a goal change.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/learning_curves.png}
    \caption{Learning curves comparing ARC-modulated Q-learning vs baseline across 3 GridWorld environments.}
    \label{fig:learning_curves}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/sensitivity_controller.png}
    \caption{Performance distribution by controller type. ARC variants consistently outperform baselines with lower variance.}
    \label{fig:sensitivity_controller}
\end{figure}

\subsection{Controller Comparison}
We analyzed 15 controllers (see Figure \ref{fig:performance} and Figure \ref{fig:radar}).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/fig_controller_performance.png}
    \caption{Performance comparison. LQR (0.96) and Robust (0.95) outperform baselines.}
    \label{fig:performance}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/fig_controller_rumination.png}
    \caption{Rumination Index (RI) by controller. Integral and robust/adaptive controllers eliminate perseverative loops (RI $\approx 0$).}
    \label{fig:rumination}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/fig_controller_tradeoff.png}
    \caption{Trade-off between performance and anti-rumination. Bubble size indicates control effort; robust control achieves a strong balance.}
    \label{fig:tradeoff}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/fig_controller_effort.png}
    \caption{Control effort by controller. Meta-control reduces effort while maintaining stability.}
    \label{fig:effort}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/fig_controller_radar.png}
    \caption{Multi-dimensional comparison of top 5 controllers.}
    \label{fig:radar}
\end{figure}

\section{Conclusion}
We presented ARC, a homeostatic control framework for agents with internal affective states. Experiments demonstrate that affective states without regulation lead to collapse, while ARC maintains stability, efficiency, and safety.

\bibliography{references}

\appendix
\section{Reproducibility}
All code and data available at \url{https://github.com/edamianreynoso/arc-assb-controller}.

\section{State Dynamics}
\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/state_dynamics.png}
    \caption{State dynamics in ChangingGoalGridWorld.}
    \label{fig:state_dynamics}
\end{figure}

\section{Metric Correlations (Heatmap)}

To validate the theoretical relationships between our proposed metrics, we analyzed Pearson correlations across all experimental runs. The combined heatmap is computed by concatenating run-level metrics CSVs from L1--L5 plus L4\_meta (see \texttt{experiments/analyze\_correlations.py}).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/correlation_combined.png}
    \caption{Correlation heatmap aggregated across all experimental runs (L1--L5 + L4\_meta). Key correlations include PerfMean $\leftrightarrow$ RI ($r=-0.59$), RT $\leftrightarrow$ RI ($r=+0.44$), and RI $\leftrightarrow$ NDR ($r=+0.92$).}
    \label{fig:heatmap}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/correlation_L1.png}
    \caption{Metric correlation heatmap for L1 runs only (stability line).}
    \label{fig:heatmap_l1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/correlation_L2.png}
    \caption{Metric correlation heatmap for L2 runs only (memory \& continual learning line).}
    \label{fig:heatmap_l2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/correlation_L3.png}
    \caption{Metric correlation heatmap for L3 runs only (anti-rumination stress tests line).}
    \label{fig:heatmap_l3}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/correlation_L4.png}
    \caption{Metric correlation heatmap for L4 runs only (meta-control efficiency line).}
    \label{fig:heatmap_l4}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/correlation_L4_meta.png}
    \caption{Metric correlation heatmap for meta-control-focused runs (L4\_meta).}
    \label{fig:heatmap_l4_meta}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/correlation_L5.png}
    \caption{Metric correlation heatmap for L5 runs only (adversarial safety line).}
    \label{fig:heatmap_l5}
\end{figure}

\section{Supplementary Figures}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/metrics_comparison.png}
    \caption{Final metrics comparison for RL transfer in ChangingGoalGridWorld. Stars mark the winner per metric.}
    \label{fig:metrics_comparison}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig_heatmap_perfmean.png}
    \caption{Heatmap of mean performance (PerfMean) across 15 controllers and 10 scenarios.}
    \label{fig:heatmap_perfmean}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig_heatmap_ri.png}
    \caption{Heatmap of Rumination Index (RI) across 15 controllers and 10 scenarios.}
    \label{fig:heatmap_ri}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig_heatmap_rt.png}
    \caption{Heatmap of Recovery Time (RT) across 15 controllers and 10 scenarios.}
    \label{fig:heatmap_rt}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/fig_heatmap_effort.png}
    \caption{Heatmap of Control Effort across 15 controllers and 10 scenarios.}
    \label{fig:heatmap_effort}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/efficiency_comparison.png}
    \caption{Learning speed comparison: both agents reach 100\% success, but ARC converges faster in benign environments.}
    \label{fig:efficiency}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/sensitivity_scenario.png}
    \caption{Scenario difficulty analysis (ARC only): performance, rumination, and recovery vary by stressor type.}
    \label{fig:sensitivity_scenario}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/sensitivity_variance.png}
    \caption{Variance sensitivity across seeds. Lower variance indicates more reliable behavior.}
    \label{fig:sensitivity_variance}
\end{figure}

\clearpage
\section{Configuration Parameters}

Default parameters used in all experiments (from \texttt{configs/v2.yaml}):

\begin{center}
{\small
\begin{tabular}{lll}
    \toprule
    Parameter & Value & Description \\
    \midrule
    \texttt{a\_safe} & 0.60 & Arousal safety threshold \\
    \texttt{s\_safe} & 0.55 & Narrative safety threshold \\
    \texttt{s\_rum\_tau} & 0.55 & Rumination threshold \\
    \texttt{arc\_w\_u} & 0.40 & Weight for uncertainty in risk \\
    \texttt{arc\_w\_a} & 0.30 & Weight for arousal in risk \\
    \texttt{arc\_w\_s} & 0.35 & Weight for narrative in risk \\
    \texttt{arc\_k\_dmg} & 0.95 & DMN suppression gain \\
    \texttt{arc\_k\_calm} & 0.85 & Calming gain \\
    \texttt{arc\_k\_att} & 0.75 & Attention boost gain \\
    \texttt{horizon} & 160 & Episode length (simulation) \\
    \texttt{shock\_t} & 60 & Perturbation onset time \\
    \bottomrule
\end{tabular}}
\end{center}

\clearpage
\section{Detailed Benchmark Results}

This appendix provides full performance data for all 15 controller architectures across validated scenarios. Tables below compare Performance (Perf), Rumination Index (RI), Narrative Dominance (NDR), Recovery Time (RecovTime), and Control Effort (Effort).

\subsection{Line 1: Stability (Value Shocks and Uncertainty)}

\subsubsection{Scenario: Reward Flip}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & RecovTime & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.998 & 0.000 & 0.000 & 1.587 \\
    \texttt{arc\_ultimate} & 0.995 & 0.000 & 0.000 & 1.027 \\
    \texttt{arc\_v2\_hier} & 0.994 & 1.377 & 4.300 & 0.390 \\
    \texttt{arc\_v1\_lqr} & 0.994 & 1.386 & 0.000 & 0.494 \\
    \texttt{arc\_v1} & 0.994 & 0.000 & 3.450 & 0.508 \\
    \texttt{arc\_robust} & 0.994 & 0.000 & 0.000 & 0.744 \\
    \texttt{arc\_v3\_meta} & 0.993 & 0.000 & 0.000 & 0.353 \\
    \texttt{arc\_v1\_lqi} & 0.991 & 0.000 & 0.000 & 0.773 \\
    \texttt{arc\_v2\_lqi} & 0.991 & 0.000 & 0.000 & 0.784 \\
    \texttt{arc\_v1\_pid} & 0.991 & 0.000 & 0.000 & 2.257 \\
    \texttt{arc\_v3\_pid\_meta} & 0.978 & 0.000 & 1.900 & 1.257 \\
    \texttt{perf\_optimized} & 0.880 & 1.394 & 100.000 & 0.700 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.859 & 1.407 & 95.050 & 0.492 \\
    \texttt{naive\_calm} & 0.508 & 1.408 & 0.050 & 0.149 \\
    \texttt{no\_control} & 0.415 & 1.408 & 100.000 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsubsection{Scenario: Noise Burst}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & RecovTime & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.998 & 0.000 & 0.000 & 1.605 \\
    \texttt{arc\_ultimate} & 0.995 & 0.000 & 0.000 & 1.106 \\
    \texttt{arc\_robust} & 0.993 & 0.000 & 1.300 & 0.785 \\
    \texttt{arc\_v3\_meta} & 0.993 & 0.051 & 25.000 & 0.399 \\
    \texttt{arc\_v1\_lqr} & 0.993 & 1.386 & 1.250 & 0.566 \\
    \texttt{arc\_v1\_lqi} & 0.991 & 0.000 & 0.000 & 0.905 \\
    \texttt{arc\_v2\_lqi} & 0.991 & 0.000 & 0.000 & 0.915 \\
    \texttt{arc\_v1\_pid} & 0.991 & 0.000 & 0.000 & 2.257 \\
    \texttt{arc\_v1} & 0.989 & 0.000 & 32.100 & 0.550 \\
    \texttt{arc\_v2\_hier} & 0.987 & 1.263 & 33.050 & 0.444 \\
    \texttt{arc\_v3\_pid\_meta} & 0.972 & 0.000 & 29.500 & 1.290 \\
    \texttt{perf\_optimized} & 0.880 & 1.394 & 100.000 & 0.700 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.848 & 1.407 & 100.000 & 0.585 \\
    \texttt{naive\_calm} & 0.365 & 1.408 & 100.000 & 0.177 \\
    \texttt{no\_control} & 0.259 & 1.408 & 100.000 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsubsection{Scenario: Sudden Threat}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & RecovTime & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.989 & 0.013 & 0.000 & 1.707 \\
    \texttt{arc\_ultimate} & 0.968 & 0.010 & 0.000 & 1.298 \\
    \texttt{arc\_v1\_pid} & 0.964 & 0.000 & 0.000 & 2.410 \\
    \texttt{arc\_v1\_lqi} & 0.964 & 0.008 & 0.000 & 1.222 \\
    \texttt{arc\_v2\_lqi} & 0.963 & 0.008 & 0.000 & 1.173 \\
    \texttt{arc\_robust} & 0.959 & 0.005 & 0.550 & 1.252 \\
    \texttt{arc\_v1\_lqr} & 0.949 & 1.386 & 0.050 & 1.088 \\
    \texttt{arc\_v3\_meta} & 0.936 & 0.000 & 100.000 & 0.783 \\
    \texttt{arc\_v1} & 0.914 & 0.000 & 100.000 & 1.054 \\
    \texttt{arc\_v3\_pid\_meta} & 0.908 & 0.000 & 100.000 & 1.643 \\
    \texttt{arc\_v2\_hier} & 0.907 & 1.333 & 85.000 & 0.864 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.890 & 1.407 & 100.000 & 1.370 \\
    \texttt{perf\_optimized} & 0.825 & 1.394 & 100.000 & 0.700 \\
    \texttt{naive\_calm} & 0.252 & 1.408 & 100.000 & 0.262 \\
    \texttt{no\_control} & 0.217 & 1.408 & 100.000 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsection{Line 2: Memory and Continuous Learning}

\subsubsection{Scenario: Distribution Shift}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Retention & Rumination & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.998 & 1.000 & 0.000 & 1.645 \\
    \texttt{arc\_ultimate} & 0.995 & 1.000 & 0.000 & 1.186 \\
    \texttt{arc\_v1\_lqi} & 0.991 & 1.000 & 0.000 & 0.999 \\
    \texttt{arc\_v2\_lqi} & 0.991 & 1.000 & 0.000 & 1.008 \\
    \texttt{arc\_v1\_pid} & 0.991 & 1.000 & 0.000 & 2.296 \\
    \texttt{arc\_robust} & 0.985 & 1.000 & 0.000 & 0.892 \\
    \texttt{arc\_v1\_lqr} & 0.984 & 1.000 & 1.386 & 0.695 \\
    \texttt{arc\_v3\_meta} & 0.982 & 1.000 & 0.057 & 0.486 \\
    \texttt{arc\_v1} & 0.972 & 1.000 & 0.000 & 0.674 \\
    \texttt{arc\_v2\_hier} & 0.968 & 1.000 & 1.258 & 0.548 \\
    \texttt{arc\_v3\_pid\_meta} & 0.959 & 1.000 & 0.000 & 1.372 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.871 & 0.989 & 1.407 & 0.739 \\
    \texttt{perf\_optimized} & 0.869 & 0.943 & 1.394 & 0.700 \\
    \texttt{naive\_calm} & 0.276 & 0.155 & 1.408 & 0.200 \\
    \texttt{no\_control} & 0.199 & 0.000 & 1.408 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsubsection{Scenario: Goal Conflict}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Retention & Rumination & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.997 & 1.000 & 0.000 & 1.620 \\
    \texttt{arc\_ultimate} & 0.993 & 1.000 & 0.000 & 1.134 \\
    \texttt{arc\_v1\_lqr} & 0.993 & 1.000 & 1.408 & 0.544 \\
    \texttt{arc\_robust} & 0.992 & 1.000 & 0.000 & 0.785 \\
    \texttt{arc\_v3\_meta} & 0.991 & 1.000 & 0.000 & 0.388 \\
    \texttt{arc\_v1\_lqi} & 0.991 & 1.000 & 0.000 & 0.938 \\
    \texttt{arc\_v2\_lqi} & 0.991 & 1.000 & 0.000 & 0.947 \\
    \texttt{arc\_v1} & 0.990 & 1.000 & 0.000 & 0.555 \\
    \texttt{arc\_v1\_pid} & 0.990 & 1.000 & 0.000 & 2.270 \\
    \texttt{arc\_v2\_hier} & 0.989 & 1.000 & 1.410 & 0.430 \\
    \texttt{arc\_v3\_pid\_meta} & 0.976 & 1.000 & 0.000 & 1.289 \\
    \texttt{perf\_optimized} & 0.873 & 0.957 & 1.417 & 0.700 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.822 & 0.980 & 1.434 & 0.529 \\
    \texttt{naive\_calm} & 0.420 & 0.452 & 1.434 & 0.162 \\
    \texttt{no\_control} & 0.326 & 0.344 & 1.434 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsection{Line 3: Anti-Rumination (Narrative Loops)}

\subsubsection{Scenario: Sustained Contradiction}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & NarrDom & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.981 & 0.003 & 0.000 & 1.974 \\
    \texttt{arc\_ultimate} & 0.934 & 0.000 & 0.000 & 1.534 \\
    \texttt{arc\_v1\_lqi} & 0.929 & 0.000 & 0.000 & 1.420 \\
    \texttt{arc\_v2\_lqi} & 0.922 & 0.000 & 0.000 & 1.384 \\
    \texttt{arc\_v1\_lqr} & 0.904 & 1.472 & 0.881 & 1.417 \\
    \texttt{arc\_v1\_pid} & 0.886 & 0.000 & 0.000 & 2.531 \\
    \texttt{arc\_v3\_meta} & 0.879 & 0.101 & 0.000 & 0.979 \\
    \texttt{arc\_robust} & 0.868 & 0.000 & 0.000 & 1.465 \\
    \texttt{arc\_v2\_hier} & 0.837 & 1.449 & 0.821 & 1.112 \\
    \texttt{arc\_v1} & 0.817 & 0.000 & 0.000 & 1.278 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.801 & 1.472 & 0.842 & 1.790 \\
    \texttt{perf\_optimized} & 0.790 & 1.472 & 0.957 & 0.700 \\
    \texttt{arc\_v3\_pid\_meta} & 0.753 & 0.000 & 0.000 & 1.793 \\
    \texttt{naive\_calm} & 0.018 & 1.472 & 0.987 & 0.380 \\
    \texttt{no\_control} & 0.014 & 1.472 & 0.987 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsubsection{Scenario: Gaslighting}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & NarrDom & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.998 & 0.000 & 0.000 & 1.816 \\
    \texttt{arc\_ultimate} & 0.992 & 0.000 & 0.000 & 1.196 \\
    \texttt{arc\_v1\_lqi} & 0.988 & 0.000 & 0.000 & 0.977 \\
    \texttt{arc\_v2\_lqi} & 0.988 & 0.000 & 0.000 & 0.986 \\
    \texttt{arc\_v1\_pid} & 0.987 & 0.000 & 0.000 & 2.357 \\
    \texttt{arc\_robust} & 0.985 & 0.000 & 0.000 & 0.854 \\
    \texttt{arc\_v1\_lqr} & 0.983 & 1.417 & 0.810 & 0.649 \\
    \texttt{arc\_v3\_meta} & 0.982 & 0.027 & 0.000 & 0.453 \\
    \texttt{arc\_v1} & 0.980 & 0.000 & 0.000 & 0.634 \\
    \texttt{arc\_v2\_hier} & 0.978 & 0.848 & 0.521 & 0.515 \\
    \texttt{arc\_v3\_pid\_meta} & 0.962 & 0.000 & 0.000 & 1.344 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.865 & 1.430 & 0.745 & 0.677 \\
    \texttt{perf\_optimized} & 0.865 & 1.422 & 0.814 & 0.700 \\
    \texttt{naive\_calm} & 0.258 & 1.431 & 0.818 & 0.194 \\
    \texttt{no\_control} & 0.171 & 1.431 & 0.877 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsubsection{Scenario: Instruction Conflict}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & NarrDom & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.976 & 0.000 & 0.000 & 1.892 \\
    \texttt{arc\_ultimate} & 0.912 & 0.000 & 0.000 & 1.380 \\
    \texttt{arc\_v1\_lqr} & 0.894 & 1.444 & 0.697 & 1.192 \\
    \texttt{arc\_v1\_lqi} & 0.877 & 0.000 & 0.000 & 1.140 \\
    \texttt{arc\_v2\_lqi} & 0.866 & 0.000 & 0.000 & 1.146 \\
    \texttt{arc\_robust} & 0.854 & 0.000 & 0.000 & 1.242 \\
    \texttt{perf\_optimized} & 0.839 & 1.445 & 0.964 & 0.700 \\
    \texttt{arc\_v1\_pid} & 0.839 & 0.000 & 0.000 & 2.415 \\
    \texttt{arc\_v3\_meta} & 0.835 & 0.248 & 0.000 & 0.820 \\
    \texttt{arc\_v2\_hier} & 0.830 & 1.429 & 0.663 & 0.919 \\
    \texttt{arc\_v1} & 0.826 & 0.359 & 0.000 & 1.010 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.798 & 1.453 & 0.676 & 1.535 \\
    \texttt{arc\_v3\_pid\_meta} & 0.792 & 0.000 & 0.000 & 2.020 \\
    \texttt{naive\_calm} & 0.076 & 1.453 & 0.694 & 0.369 \\
    \texttt{no\_control} & 0.034 & 1.453 & 0.969 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsection{Line 5: Adversarial Safety}

\subsubsection{Scenario: Adversarial Coupling}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & NarrDom & Effort \\
    \midrule
    \texttt{arc\_v1} & 0.963 & 0.000 & 0.000 & 0.719 \\
    \texttt{arc\_v2\_hier} & 0.962 & 0.628 & 0.271 & 0.594 \\
    \texttt{arc\_robust} & 0.917 & 0.000 & 0.000 & 1.269 \\
    \texttt{arc\_v1\_lqr} & 0.915 & 1.481 & 0.497 & 1.235 \\
    \texttt{arc\_v3\_meta} & 0.914 & 0.159 & 0.000 & 0.838 \\
    \texttt{arc\_v3\_pid\_meta} & 0.902 & 0.000 & 0.000 & 2.074 \\
    \texttt{perf\_optimized} & 0.867 & 1.481 & 0.972 & 0.700 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.848 & 1.476 & 0.894 & 0.514 \\
    \texttt{no\_control} & 0.409 & 1.470 & 0.956 & 0.000 \\
    \texttt{arc\_adaptive} & 0.193 & 0.008 & 0.000 & 2.331 \\
    \texttt{arc\_v1\_pid} & 0.139 & 0.000 & 0.000 & 2.729 \\
    \texttt{arc\_v1\_lqi} & 0.139 & 0.005 & 0.001 & 1.820 \\
    \texttt{arc\_v2\_lqi} & 0.138 & 0.004 & 0.001 & 1.859 \\
    \texttt{arc\_ultimate} & 0.134 & 0.006 & 0.001 & 1.971 \\
    \texttt{naive\_calm} & 0.073 & 1.475 & 0.495 & 0.332 \\
    \bottomrule
\end{tabular}}
\end{center}

\subsubsection{Scenario: Random Dopamine}

\begin{center}
{\scriptsize
\begin{tabular}{lrrrr}
    \toprule
    Controller & Perf & Rumination & NarrDom & Effort \\
    \midrule
    \texttt{arc\_adaptive} & 0.976 & 0.000 & 0.000 & 2.150 \\
    \texttt{arc\_ultimate} & 0.946 & 0.000 & 0.000 & 1.435 \\
    \texttt{arc\_v1\_lqr} & 0.943 & 1.456 & 0.743 & 0.940 \\
    \texttt{arc\_robust} & 0.932 & 0.000 & 0.000 & 1.006 \\
    \texttt{arc\_v1\_pid} & 0.922 & 0.000 & 0.000 & 2.450 \\
    \texttt{arc\_v1\_lqi} & 0.916 & 0.000 & 0.000 & 1.173 \\
    \texttt{arc\_v2\_lqi} & 0.916 & 0.000 & 0.000 & 1.227 \\
    \texttt{arc\_v3\_meta} & 0.905 & 0.259 & 0.000 & 0.646 \\
    \texttt{arc\_v1} & 0.897 & 1.124 & 0.581 & 0.787 \\
    \texttt{arc\_v2\_hier} & 0.894 & 1.207 & 0.620 & 0.720 \\
    \texttt{arc\_v3\_pid\_meta} & 0.870 & 0.000 & 0.000 & 1.624 \\
    \texttt{perf\_optimized} & 0.861 & 1.457 & 0.958 & 0.700 \\
    \texttt{arc\_v3\_lqr\_meta} & 0.817 & 1.458 & 0.717 & 1.192 \\
    \texttt{naive\_calm} & 0.119 & 1.460 & 0.763 & 0.328 \\
    \texttt{no\_control} & 0.040 & 1.460 & 0.950 & 0.000 \\
    \bottomrule
\end{tabular}}
\end{center}

\end{document}
